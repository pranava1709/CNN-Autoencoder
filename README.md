# CNN-Autoencoder

In recent times Autoencoders have been extremely beneficial, especially in producing reduced dimensional images. Here, I tried to develop a combination of an autoencoder and CNN from scratch using the basic encoder and decoder base, for three main categories of the Dar Matter sphere, vort, and no sub-structure. 

This pipeline is implemented in Keras, and the model is trained on 100 epochs. 

# Dataset

The dataset is a combination of the above three mentioned classes containing a total of 1200 training samples in .npy format.





# Results 

The results produced by the model are efficient and have attached both the validation image and resulted in the image for each class. The first figure in each case is the ground truth image and the second one is the predicted one.)

No-substructure (

![1nos](https://github.com/pranava1709/CNN-Autoencoder/assets/60814171/f557354d-296a-4135-8e72-8b67353c4e41)


![11nos](https://github.com/pranava1709/CNN-Autoencoder/assets/60814171/1a4e5df9-ed74-4f02-9741-dbd268b66ed7)


Sphere

![1sp](https://github.com/pranava1709/CNN-Autoencoder/assets/60814171/7ac191d5-dcac-450e-b9ec-5124aa9a6b49)


![11sp](https://github.com/pranava1709/CNN-Autoencoder/assets/60814171/a357f133-8b21-4839-8678-75ca18dd82d7)


Vort 

![1vort](https://github.com/pranava1709/CNN-Autoencoder/assets/60814171/71c8750a-a2cb-4440-ae8d-b3d2e286a456)


![11vort](https://github.com/pranava1709/CNN-Autoencoder/assets/60814171/36a4b289-fe79-4375-9845-653561a74b15)


